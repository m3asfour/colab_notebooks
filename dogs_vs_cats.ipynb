{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dogs_vs_catsipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammed3asfour/colab_notebooks/blob/master/dogs_vs_cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rq3AelNEm844",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "!mkdir ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XVZHm1mZm999",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"\",\"key\":\"\"}  # insert token information from kaggle\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sRmyPRwXnBSG",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oObT4E_5nFli",
        "colab": {}
      },
      "source": [
        "!kaggle competitions download -c dogs-vs-cats -p /content\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab_type": "code",
        "id": "UE-pbpUHm46s",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization, Input, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import Callback\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.initializers import he_normal\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JP7R1CudAkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls train/ -U | head -5  # view sample images filenames - bash command"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkeqeB8-mDft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '../content/train/'  # the images directory\n",
        "images_names = os.listdir(path)  # names of the files in the directory\n",
        "images_num = len(images_names)\n",
        "print(f'Number of images: {images_num}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNRnmyKFaDrI",
        "colab_type": "text"
      },
      "source": [
        "Since there's a large number of images given the kernel's resources, we'll just make keras feed the model from the directory directly instead of loading them into an np.array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UykCyUoOhdtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of images to use for plt.imshow\n",
        "width, height, channels = 256, 256, 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab_type": "code",
        "id": "QxcXkBAom46x",
        "colab": {}
      },
      "source": [
        "images_samples = np.zeros((4, height, width, 3), dtype=int)\n",
        "samples_labels = []\n",
        "# get random 4 images\n",
        "for i in range(4):\n",
        "    rnd_img = np.random.randint(0, images_num)\n",
        "    img_filename = images_names[rnd_img]\n",
        "    img_bgr = cv2.imread(path + img_filename)  # loads the images channels in (blue, green, red) order\n",
        "    images_samples[i] = cv2.resize(src=img_bgr[:, :, [2, 1, 0]], dsize=(width, height))  # store the random image\n",
        "    samples_labels.append(img_filename[:3])  # store the random images' label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_1PUQ5gm46-",
        "colab": {}
      },
      "source": [
        "# view the 4 samples\n",
        "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "for ax, img, label in zip(axs.ravel(), images_samples, samples_labels):\n",
        "    ax.imshow(img);\n",
        "    ax.set_title(f'Class: {label}', size=15);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ga0IE2aqxl",
        "colab_type": "text"
      },
      "source": [
        "Note that there are mislabelled data in the dataset so don't worry if you see an image with the wrong label. You just got unlucky while picking random samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqx09j9goa6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create subdirectories to use as classes for keras to feed the model - bash command\n",
        "!mkdir $path/cats\n",
        "!mkdir $path/dogs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeBAXuTNuR6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# move the images to their corresponding subdirectories - bash command\n",
        "!cp $path/cat.* $path/cats/\n",
        "!cp $path/dog.* $path/dogs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3r10dlfxGRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the directory - bash command\n",
        "# !ls $path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lMfIeJ8bomL",
        "colab_type": "text"
      },
      "source": [
        "We'll augment the images to get more training data for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EUmdySDHm47h",
        "colab": {}
      },
      "source": [
        "def scale_images(x):\n",
        "  return x / 255\n",
        "\n",
        "# Augmentation Ranges\n",
        "transform_params = {\n",
        "    'featurewise_center': False,\n",
        "    'featurewise_std_normalization': False,\n",
        "    'samplewise_center': False,\n",
        "    'samplewise_std_normalization': False,\n",
        "    'rotation_range': 30, \n",
        "    'width_shift_range': 0.15, \n",
        "    'height_shift_range': 0.15,\n",
        "    'horizontal_flip': True,\n",
        "    'validation_split': 0.25,\n",
        "    'preprocessing_function': scale_images\n",
        "}\n",
        "img_gen = ImageDataGenerator(**transform_params) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4b0HWbt06SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_lITVFYVm47o",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2, 4, figsize=(20,10))  # let's see 4 augmentation examples\n",
        "fig.suptitle('Augmentation Results', size=32)\n",
        "\n",
        "for axs_col in range(axs.shape[1]):\n",
        "    viz_transoform_params = {  # defined each iteration to get new augmentation values each time\n",
        "        'theta': np.random.randint(-transform_params['rotation_range'], transform_params['rotation_range']),\n",
        "        'tx': np.random.uniform(0, transform_params['width_shift_range']),\n",
        "        'ty': np.random.uniform(0, transform_params['height_shift_range']),\n",
        "        'flip_horizontal': np.random.choice([True, False], p=[0.5, 0.5])\n",
        "    }\n",
        "\n",
        "    img = images_samples[axs_col]  # the original image\n",
        "    aug_img = img_gen.apply_transform(img, viz_transoform_params)  # the same image after augmentation\n",
        "    \n",
        "    axs[0, axs_col].imshow(img);\n",
        "    axs[0, axs_col].set_title('Original Image', size=15)\n",
        "    \n",
        "    axs[1, axs_col].imshow(aug_img);\n",
        "    axs[1, axs_col].set_title('Augmented Image', size=15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0LlwePZ6CBYH",
        "colab": {}
      },
      "source": [
        "def conv_block(x, filters, kernel_size, strides, layer_no, add_pool=False):\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, name=f'conv{layer_no}', \n",
        "               padding='same', kernel_initializer=he_normal(layer_no))(x)\n",
        "    x = Activation('relu', name=f'activation{layer_no}')(x)\n",
        "    x = BatchNormalization(name=f'bn{layer_no}')(x)\n",
        "    if add_pool:\n",
        "        x = MaxPooling2D(pool_size=[2, 2], strides=[2, 2], padding='same')(x)\n",
        "    x = Dropout(0.25, name=f'ConvDropout{layer_no}')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYegF7sim47z",
        "colab": {}
      },
      "source": [
        "# a Fully connected layer with activation, batchnorm and dropout\n",
        "def dense_block(x, neurons, layer_no):\n",
        "    x = Dense(neurons, kernel_initializer=he_normal(layer_no), name=f'Dense{layer_no}')(x)\n",
        "    x = Activation('relu', name=f'Relu{layer_no}')(x)\n",
        "    x = BatchNormalization(name=f'BatchNorm{layer_no}')(x)\n",
        "    x = Dropout(0.5, name=f'Dropout{layer_no}')(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l1QYGqp0m473",
        "colab": {}
      },
      "source": [
        "def create_model(shape):\n",
        "    input_layer = Input(shape, name='input_layer')  # input layer with given shape\n",
        "    \n",
        "    # load ResNet50 with initialized weights and remove final dense layers - keep as trainable layers\n",
        "    resnet = ResNet50(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
        "\n",
        "    # dense layers after the ResNet50 initialized layers\n",
        "    flat1 = Flatten(name='Flatten')(resnet.output)\n",
        "    flat_bn = BatchNormalization()(flat1)\n",
        "    drop1 = Dropout(0.5)(flat_bn)\n",
        "    dens1 = dense_block(drop1, neurons=512, layer_no=1)\n",
        "    dens2 = dense_block(dens1, neurons=256, layer_no=3)\n",
        "    \n",
        "    dens4 = Dense(1, name='Dense4')(dens2)\n",
        "    output_layer = Activation('sigmoid')(dens4)\n",
        "    \n",
        "    model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "35sWNtvlm48P",
        "colab": {}
      },
      "source": [
        "# used to plot training curves (accuracy, loss) while model is training\n",
        "class Plotter(Callback):\n",
        "    def plot(self):  # Updates the graph\n",
        "        clear_output(wait=True)\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "        \n",
        "        # plot the losses\n",
        "        ax1.plot(self.epochs, self.losses, label='train_loss')\n",
        "        ax1.plot(self.epochs, self.val_losses, label='val_loss')\n",
        "        \n",
        "        # plot the accuracies\n",
        "        ax2.plot(self.epochs, self.acc, label='train_acc')\n",
        "        ax2.plot(self.epochs, self.val_acc, label='val_acc')\n",
        "    \n",
        "        ax1.set_title(f'Loss vs Epochs')\n",
        "        ax1.set_xlabel(\"Epochs\")\n",
        "        ax1.set_ylabel(\"Loss\")\n",
        "        \n",
        "        ax2.set_title(f'Accuracy vs Epochs')\n",
        "        ax2.set_xlabel(\"Epoches\")\n",
        "        ax2.set_ylabel(\"Accuracy\")\n",
        "        \n",
        "        ax1.legend()\n",
        "        ax2.legend()\n",
        "        plt.show()\n",
        "        \n",
        "        # print out the accuracies at each epoch\n",
        "        print(f'Epoch #{self.epochs[-1]+1} >> train_acc={self.acc[-1]*100:.3f}%, train_loss={self.losses[-1]:.5f}')\n",
        "        print(f'Epoch #{self.epochs[-1]+1} >> val_acc={self.val_acc[-1]*100:.3f}%, val_loss={self.val_losses[-1]:.5f}')\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        # initialize lists to store values from training\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.epochs = []\n",
        "        self.batch_no = []\n",
        "        self.acc = []\n",
        "        self.val_acc = []\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # append values from the last epoch\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acc.append(logs.get('acc'))\n",
        "        self.val_acc.append(logs.get('val_acc'))\n",
        "        self.epochs.append(epoch)\n",
        "        self.plot()  # update the graph\n",
        "        \n",
        "    def on_train_end(self, logs={}):\n",
        "        self.plot()\n",
        "               \n",
        "plotter = Plotter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aoPAkm6ym48L",
        "colab": {}
      },
      "source": [
        "# used to decrease the learning rate if val_acc doesn't enhance\n",
        "plateau_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.75,\n",
        "                              patience=1, min_lr=0.000001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YidIMiyjm48U",
        "colab": {}
      },
      "source": [
        "callbacks = [plotter, plateau_reduce] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue17z2dYR-6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyperparameters\n",
        "height, width, channels_num = 256, 256, 3\n",
        "learning_rate = 0.00005\n",
        "epochs = 10\n",
        "batch_size = 64  # if increased you may run out of gpu memory - reduce image size if you want to increase the batch size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ne2rrapUm48C",
        "colab": {}
      },
      "source": [
        "model = create_model((height, width, channels_num))\n",
        "optimizer = Adam(learning_rate)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQjS2O0lm48f",
        "colab": {}
      },
      "source": [
        "# used to feed the model augmented training data after being loaded from the directory\n",
        "train_gen = img_gen.flow_from_directory(directory=path, target_size=(height, width), color_mode='rgb', classes=['cats', 'dogs'], \n",
        "                                        class_mode='binary', batch_size=batch_size, shuffle=True, subset='training', interpolation='nearest')\n",
        "\n",
        "# used to feed the model augmented validation data after being loaded from the directory\n",
        "valid_gen = img_gen.flow_from_directory(directory=path, target_size=(height, width), color_mode='rgb', classes=['cats', 'dogs'], \n",
        "                                        class_mode='binary', batch_size=batch_size, shuffle=True, subset='validation', interpolation='nearest')\n",
        "\n",
        "\n",
        "model.fit_generator(train_gen, validation_data=valid_gen, epochs=epochs, \n",
        "                        steps_per_epoch=images_num*0.75//batch_size + 1, \n",
        "                        validation_steps=images_num*0.25//batch_size + 1, callbacks=callbacks)\n",
        "\n",
        "model.save('my_resnet_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h65JqXRhNpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjjUn5IThkDu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # use if you don't want to retrain the model for visualization only\n",
        "# model = load_model('my_resnet_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iesfBnzH9qvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check the corresponding classes of the binary encoding\n",
        "train_gen.class_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y47X0K8rH0DE",
        "colab": {}
      },
      "source": [
        "# get first 4 convolutional layers to visualize their activations\n",
        "layers_viz = []\n",
        "for layer in model.layers:\n",
        "  if len(layers_viz) < 4:\n",
        "    if layer.__class__.__name__ == 'Conv2D':\n",
        "      layers_viz.append(layer)\n",
        "  else:\n",
        "    break\n",
        "\n",
        "# using keras backend functions to obtain layers activtions - check keras documentation\n",
        "inp = model.input\n",
        "outputs = [layer.output for layer in layers_viz]\n",
        "functor = K.function([inp, K.learning_phase()], outputs)\n",
        "test_idx = np.random.randint(0, images_samples.shape[0])\n",
        "test_img = images_samples[test_idx]\n",
        "test_img = test_img.reshape(1, *test_img.shape)\n",
        "print(test_img.shape)\n",
        "layers_outs = functor([test_img, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kysiI0XtjVhM",
        "colab": {}
      },
      "source": [
        "# shapes of the selected layers' activations\n",
        "for layer in layers_outs:\n",
        "  print(layer.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MXPkF40Ampci",
        "colab": {}
      },
      "source": [
        "# plots activations in a grid of axes\n",
        "def plot_activations(conv_layer):\n",
        "  dim_sqrt = np.sqrt(conv_layer.shape[-1])\n",
        "  rows_num = int(dim_sqrt)  # get integer number of rows\n",
        "  cols_num = conv_layer.shape[-1] // rows_num\n",
        "  fig, axs = plt.subplots(rows_num, cols_num, figsize=(16, 16))\n",
        "  for filter_map, ax in zip(range(conv_layer.shape[-1]), axs.ravel()):\n",
        "    activations = conv_layer[0, :, :, filter_map]\n",
        "    activations = (activations - np.min(activations)) / (np.max(activations - np.min(activations)))  # normalize to give to plt.imshow \n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(activations, cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1YLEXjZu5-eh",
        "colab": {}
      },
      "source": [
        "# get a random sample from the 4 samples\n",
        "test_idx = np.random.randint(0, images_samples.shape[0]-1)\n",
        "test_img = images_samples[test_idx]\n",
        "test_img = test_img.reshape(1, *test_img.shape)\n",
        "layers_outs = functor([test_img, 0])  # the output of the keras functor we made - the activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qavSglJdupdU",
        "colab": {}
      },
      "source": [
        "# the 1st conv layer activations\n",
        "conv_layer = layers_outs[0]\n",
        "print(f'Number of Filters: {conv_layer.shape[-1]}')\n",
        "plot_activations(conv_layer=conv_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dUq62LuvvhTR",
        "colab": {}
      },
      "source": [
        "# the 2nd conv layer activations\n",
        "conv_layer = layers_outs[1]\n",
        "print(f'Number of Filters: {conv_layer.shape[-1]}')\n",
        "plot_activations(conv_layer=conv_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QPqMAqKfvoM7",
        "colab": {}
      },
      "source": [
        "# the 3rd conv layer activations\n",
        "conv_layer = layers_outs[2]\n",
        "print(f'Number of Filters: {conv_layer.shape[-1]}')\n",
        "plot_activations(conv_layer=conv_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PoRie2q37tPu",
        "colab": {}
      },
      "source": [
        "conv_layer = layers_outs[3]\n",
        "print(f'Number of Filters: {conv_layer.shape[-1]}')\n",
        "plot_activations(conv_layer=conv_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MSCn9b53iq",
        "colab_type": "text"
      },
      "source": [
        "Test data prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "help-v8y5-tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_path = '../content/test1'  # the images directory\n",
        "test_images_names = os.listdir(test_path)  # names of the files in the directory\n",
        "test_images_num = len(test_images_names)\n",
        "print(f'Number of images: {test_images_num}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ABdF9uxwF_X0",
        "colab": {}
      },
      "source": [
        "test_ids = []\n",
        "for i, test_img_name in enumerate(test_images_names):\n",
        "    img_id = test_img_name[:-4]\n",
        "    test_ids.append(img_id)  # store the test image's id\n",
        "    clear_output(wait=True)\n",
        "    print(f'loaded id {i+1} of {test_images_num}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svigMtwf-7Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patent_dir = '../content/'\n",
        "# generator to feed the test images to model in batches - doesn't augment, just the preprocess function\n",
        "test_gen = ImageDataGenerator(preprocessing_function=scale_images).flow_from_directory(\n",
        "                                        directory=parent_dir, target_size=(height, width), color_mode='rgb', classes=['test1'],\n",
        "                                        class_mode=None, batch_size=batch_size, shuffle=False, interpolation='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy_uE2sBDcza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict_generator(test_gen)  # model predictions\n",
        "print(preds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx1VXVhuEVqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "binary_preds = (preds >= 0.5).astype(int)  # convert predictions to binary \n",
        "print(binary_preds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmcp--HeIh4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids_arr = np.array(test_ids).astype(int).reshape(-1, 1)  # reshape ids as rows\n",
        "ids_arr.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBTYKlmEJD4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_data = np.hstack([ids_arr, binary_preds])  # data to put in a dataframe for submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOG3pr_fEn9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df = pd.DataFrame(data=sub_data, columns=['id', 'label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3W_cEGkEq5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWXxbcYBIBoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_df.sort_values(by='id', inplace=True)  # order by id\n",
        "sub_df.reset_index(inplace=True, drop=True)  # reset the index\n",
        "sub_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xJGvbT_J-jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to csv\n",
        "sub_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY4PJpsNLMaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}